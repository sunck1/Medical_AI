{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "anticipated-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from os import listdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hazardous-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify0(inX, dataSet, labels, k):\n",
    "\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "\n",
    "    diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet\n",
    "\n",
    "    sqDiffMat = diffMat**2\n",
    "\n",
    "    sqDistances = sqDiffMat.sum(axis=1)\n",
    "\n",
    "    distances = sqDistances**0.5\n",
    "\n",
    "    sortedDistIndices = distances.argsort()\n",
    "\n",
    "    classCount = {}\n",
    "    for i in range(k):\n",
    "\n",
    "        voteIlabel = labels[sortedDistIndices[i]]\n",
    "\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1\n",
    "\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cleared-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "\n",
    "    returnVect = np.zeros((1, 1024))\n",
    "\n",
    "    fr = open(filename)\n",
    "\n",
    "    for i in range(32):\n",
    "\n",
    "        lineStr = fr.readline()\n",
    "\n",
    "        for j in range(32):\n",
    "            returnVect[0, 32*i+j] = int(lineStr[j])\n",
    "\n",
    "    return returnVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-medicine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-ability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "injured-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwLabels = []\n",
    "\n",
    "trainingFileList = listdir('/data/datasets/chengkun/homework/trainingDigits')\n",
    "\n",
    "m = len(trainingFileList)\n",
    "\n",
    "trainingMat = np.zeros((m, 1024))\n",
    "\n",
    "for i in range(m):\n",
    "\n",
    "    fileNameStr = trainingFileList[i]\n",
    "\n",
    "    classNumber = int(fileNameStr.split('_')[0])\n",
    "\n",
    "    hwLabels.append(classNumber)\n",
    "\n",
    "    trainingMat[i,:] = img2vector('/data/datasets/chengkun/homework/trainingDigits/%s' % (fileNameStr))\n",
    "\n",
    "\n",
    "    \n",
    "tsLabels = []\n",
    "\n",
    "testFileList = listdir('/data/datasets/chengkun/homework/testDigits')\n",
    "\n",
    "n = len(testFileList)\n",
    "\n",
    "testMat = np.zeros((n, 1024))\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    fileNameStr = testFileList[i]\n",
    "\n",
    "    classNumber = int(fileNameStr.split('_')[0])\n",
    "\n",
    "    tsLabels.append(classNumber)\n",
    "\n",
    "    testMat[i,:] = img2vector('/data/datasets/chengkun/homework/testDigits/%s' % (fileNameStr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alpha-february",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(testMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eastern-understanding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1934"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainingMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "skilled-budapest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(tsLabels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "under-liverpool",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946\n"
     ]
    }
   ],
   "source": [
    "print(len(tsLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "changed-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import re \n",
    "from collections import Counter, defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor, wait\n",
    "from functools import partial\n",
    "import mmap\n",
    "import json\n",
    "import pickle as pkl\n",
    "import gc\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold, cross_val_predict, train_test_split,GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score,recall_score, average_precision_score, roc_curve,f1_score, auc, precision_recall_fscore_support,precision_recall_curve,accuracy_score,precision_score,mean_squared_error,mean_squared_error,mean_absolute_percentage_error\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import math\n",
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "CPU_COUNT=9\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-merchant",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-montgomery",
   "metadata": {},
   "source": [
    "#### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "specialized-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unusual-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model(C,max_iter,tol):\n",
    "    \n",
    "    \n",
    "    \n",
    "    svm_model = svm.SVC(\n",
    "        max_iter= int (max_iter),\n",
    "                                    tol =  tol,\n",
    "                                C= C,\n",
    "                       probability = True,\n",
    "                        kernel = 'linear'\n",
    "                       )\n",
    "    \n",
    "    val = cross_val_score(svm_model,tr_dx,tr_dy,scoring = 'accuracy',cv = 5,n_jobs = 10).mean()\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "def tune( tasks, nb, nit, model_name, param_tune):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        #res_output = f\"{task}year_{model_name}.txt\"\n",
    "        #model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        BO = BayesianOptimization( f = SVM_model,pbounds = param_tune,verbose = 2,random_state = 1 )\n",
    "        \n",
    "        BO.maximize(n_iter=5)\n",
    "        print(BO.max)\n",
    "        return BO.max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-watershed",
   "metadata": {},
   "source": [
    "#### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sunrise-worcester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: 0 SVM\n",
      "|   iter    |  target   |     C     | max_iter  |    tol    |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9524   \u001b[0m | \u001b[0m21.43    \u001b[0m | \u001b[0m3.602e+03\u001b[0m | \u001b[0m0.0002144\u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9483   \u001b[0m | \u001b[0m15.81    \u001b[0m | \u001b[0m734.6    \u001b[0m | \u001b[0m0.09243  \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.9545   \u001b[0m | \u001b[95m10.13    \u001b[0m | \u001b[95m1.728e+03\u001b[0m | \u001b[95m0.3968   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.9462   \u001b[0m | \u001b[0m27.4     \u001b[0m | \u001b[0m2.097e+03\u001b[0m | \u001b[0m0.6853   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9524   \u001b[0m | \u001b[0m11.02    \u001b[0m | \u001b[0m4.391e+03\u001b[0m | \u001b[0m0.02748  \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.94     \u001b[0m | \u001b[0m12.4     \u001b[0m | \u001b[0m4.391e+03\u001b[0m | \u001b[0m0.8158   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9504   \u001b[0m | \u001b[0m27.08    \u001b[0m | \u001b[0m3.937e+03\u001b[0m | \u001b[0m0.175    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.94     \u001b[0m | \u001b[0m30.2     \u001b[0m | \u001b[0m1.306e+03\u001b[0m | \u001b[0m0.7468   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9421   \u001b[0m | \u001b[0m12.15    \u001b[0m | \u001b[0m778.8    \u001b[0m | \u001b[0m0.9473   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9525   \u001b[0m | \u001b[0m36.59    \u001b[0m | \u001b[0m3.643e+03\u001b[0m | \u001b[0m0.1948   \u001b[0m |\n",
      "=============================================================\n",
      "{'target': 0.9545317869415808, 'params': {'C': 10.126750357505875, 'max_iter': 1728.4580744881957, 'tol': 0.39682779748324687}}\n",
      "Tuning:\n",
      "3.0839550495147705\n",
      "Training:\n",
      "0.10509991645812988\n",
      "Predicting:\n",
      "0.0880281925201416\n",
      "Test accuracy:  0.9651162790697675\n",
      "Test recall:  0.9651162790697675\n",
      "Test precision:  0.9652463969015677\n",
      "Test f1_s:  0.9650263683867152\n"
     ]
    }
   ],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.75, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "\n",
    "        'max_iter': (1, 5000),\n",
    "        'tol': (0.0001,1),\n",
    "        'C': (1, 50)\n",
    "                }\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'SVM', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "svm_model = svm.SVC(\n",
    "            max_iter= int (params['params']['max_iter']),\n",
    "                                    tol =  params['params']['tol'],\n",
    "                                C= params['params']['C'],\n",
    "                       probability = True,\n",
    "                        kernel = 'linear',decision_function_shape='ovr'\n",
    "                       )\n",
    "\n",
    "        \n",
    "tm_st = time.time() \n",
    "svm_model.fit(tr_dx,tr_dy)\n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "tm_st = time.time()        \n",
    "test_preds = svm_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "another-costume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: 0 SVM\n",
      "|   iter    |  target   |     C     | max_iter  |    tol    |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9752   \u001b[0m | \u001b[0m21.43    \u001b[0m | \u001b[0m3.602e+03\u001b[0m | \u001b[0m0.0002144\u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9752   \u001b[0m | \u001b[0m15.81    \u001b[0m | \u001b[0m734.6    \u001b[0m | \u001b[0m0.09243  \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.9741   \u001b[0m | \u001b[0m10.13    \u001b[0m | \u001b[0m1.728e+03\u001b[0m | \u001b[0m0.3968   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.9731   \u001b[0m | \u001b[0m27.4     \u001b[0m | \u001b[0m2.097e+03\u001b[0m | \u001b[0m0.6853   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9752   \u001b[0m | \u001b[0m11.02    \u001b[0m | \u001b[0m4.391e+03\u001b[0m | \u001b[0m0.02748  \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.972    \u001b[0m | \u001b[0m4.5      \u001b[0m | \u001b[0m194.4    \u001b[0m | \u001b[0m0.8406   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9741   \u001b[0m | \u001b[0m11.74    \u001b[0m | \u001b[0m4.39e+03 \u001b[0m | \u001b[0m0.3865   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.971    \u001b[0m | \u001b[0m21.49    \u001b[0m | \u001b[0m3.602e+03\u001b[0m | \u001b[0m0.6716   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.972    \u001b[0m | \u001b[0m12.15    \u001b[0m | \u001b[0m778.8    \u001b[0m | \u001b[0m0.9473   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9741   \u001b[0m | \u001b[0m36.59    \u001b[0m | \u001b[0m3.643e+03\u001b[0m | \u001b[0m0.1948   \u001b[0m |\n",
      "=============================================================\n",
      "{'target': 0.975161583248758, 'params': {'C': 21.434078230426127, 'max_iter': 3601.9021427173484, 'tol': 0.00021436337986315216}}\n",
      "Tuning:\n",
      "4.269452810287476\n",
      "Training:\n",
      "0.5254440307617188\n",
      "Predicting:\n",
      "0.16532087326049805\n",
      "Test accuracy:  0.9756871035940803\n",
      "Test recall:  0.9756871035940803\n",
      "Test precision:  0.9759738096338071\n",
      "Test f1_s:  0.975669040792761\n"
     ]
    }
   ],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.5, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "\n",
    "        'max_iter': (1, 5000),\n",
    "        'tol': (0.0001,1),\n",
    "        'C': (1, 50)\n",
    "                }\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'SVM', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "svm_model = svm.SVC(\n",
    "            max_iter= int (params['params']['max_iter']),\n",
    "                                    tol =  params['params']['tol'],\n",
    "                                C= params['params']['C'],\n",
    "                       probability = True,\n",
    "                        kernel = 'linear',decision_function_shape='ovr'\n",
    "                       )\n",
    "\n",
    "        \n",
    "tm_st = time.time() \n",
    "svm_model.fit(tr_dx,tr_dy)\n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "tm_st = time.time()        \n",
    "test_preds = svm_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "roman-circus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: 0 SVM\n",
      "|   iter    |  target   |     C     | max_iter  |    tol    |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9766   \u001b[0m | \u001b[0m21.43    \u001b[0m | \u001b[0m3.602e+03\u001b[0m | \u001b[0m0.0002144\u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9766   \u001b[0m | \u001b[0m15.81    \u001b[0m | \u001b[0m734.6    \u001b[0m | \u001b[0m0.09243  \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.9759   \u001b[0m | \u001b[0m10.13    \u001b[0m | \u001b[0m1.728e+03\u001b[0m | \u001b[0m0.3968   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.9717   \u001b[0m | \u001b[0m27.4     \u001b[0m | \u001b[0m2.097e+03\u001b[0m | \u001b[0m0.6853   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9766   \u001b[0m | \u001b[0m11.02    \u001b[0m | \u001b[0m4.391e+03\u001b[0m | \u001b[0m0.02748  \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9724   \u001b[0m | \u001b[0m12.4     \u001b[0m | \u001b[0m4.391e+03\u001b[0m | \u001b[0m0.8158   \u001b[0m |\n",
      "| \u001b[95m7        \u001b[0m | \u001b[95m0.9772   \u001b[0m | \u001b[95m27.08    \u001b[0m | \u001b[95m3.937e+03\u001b[0m | \u001b[95m0.175    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.9731   \u001b[0m | \u001b[0m30.2     \u001b[0m | \u001b[0m1.306e+03\u001b[0m | \u001b[0m0.7468   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9738   \u001b[0m | \u001b[0m12.15    \u001b[0m | \u001b[0m778.8    \u001b[0m | \u001b[0m0.9473   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9772   \u001b[0m | \u001b[0m36.59    \u001b[0m | \u001b[0m3.643e+03\u001b[0m | \u001b[0m0.1948   \u001b[0m |\n",
      "=============================================================\n",
      "{'target': 0.9772413793103448, 'params': {'C': 27.082598095553447, 'max_iter': 3937.1326600057873, 'tol': 0.17498228480326983}}\n",
      "Tuning:\n",
      "7.626207590103149\n",
      "Training:\n",
      "0.8466277122497559\n",
      "Predicting:\n",
      "0.1896207332611084\n",
      "Test accuracy:  0.9862579281183932\n",
      "Test recall:  0.9862579281183932\n",
      "Test precision:  0.9864349124137843\n",
      "Test f1_s:  0.9862489843121065\n"
     ]
    }
   ],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.25, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "\n",
    "        'max_iter': (1, 5000),\n",
    "        'tol': (0.0001,1),\n",
    "        'C': (1, 50)\n",
    "                }\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'SVM', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "svm_model = svm.SVC(\n",
    "            max_iter= int (params['params']['max_iter']),\n",
    "                                    tol =  params['params']['tol'],\n",
    "                                C= params['params']['C'],\n",
    "                       probability = True,\n",
    "                        kernel = 'linear',decision_function_shape='ovr'\n",
    "                       )\n",
    "\n",
    "        \n",
    "tm_st = time.time() \n",
    "svm_model.fit(tr_dx,tr_dy)\n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "tm_st = time.time()        \n",
    "test_preds = svm_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-feeding",
   "metadata": {},
   "source": [
    "### Train on the whole dataset and tune the parameter individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bearing-smell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "1.5295608043670654\n",
      "Predicting:\n",
      "0.2436506748199463\n",
      "Test accuracy:  0.985200845665962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "svm_model = svm.SVC(\n",
    "                                    tol =  0.00001,\n",
    "                       probability = True,\n",
    "                        kernel = 'linear',decision_function_shape='ovr'\n",
    "                       )\n",
    "\n",
    "        \n",
    "tm_st = time.time() \n",
    "svm_model.fit(tr_dx,tr_dy)\n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "tm_st = time.time()        \n",
    "test_preds = svm_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eastern-spotlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.9948046207427979\n",
      "Predicting:\n",
      "0.18914508819580078\n",
      "Test accuracy:  0.9841437632135307\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "svm_model = svm.SVC(\n",
    "                                    tol =  0.5,\n",
    "                       probability = True,\n",
    "                        kernel = 'linear',decision_function_shape='ovr'\n",
    "                       )\n",
    "\n",
    "        \n",
    "tm_st = time.time() \n",
    "svm_model.fit(tr_dx,tr_dy)\n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "tm_st = time.time()        \n",
    "test_preds = svm_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "guilty-reliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.7527580261230469\n",
      "Predicting:\n",
      "0.16050457954406738\n",
      "Test accuracy:  0.9830866807610994\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "svm_model = svm.SVC(\n",
    "                                    tol =  1,\n",
    "                       probability = True,\n",
    "                        kernel = 'linear',decision_function_shape='ovr'\n",
    "                       )\n",
    "\n",
    "        \n",
    "tm_st = time.time() \n",
    "svm_model.fit(tr_dx,tr_dy)\n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "tm_st = time.time()        \n",
    "test_preds = svm_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "statutory-password",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "1.494490623474121\n",
      "Predicting:\n",
      "0.24400830268859863\n",
      "Test accuracy:  0.9862579281183932\n",
      "Training:\n",
      "1.5026297569274902\n",
      "Predicting:\n",
      "0.243330717086792\n",
      "Test accuracy:  0.9862579281183932\n",
      "Training:\n",
      "1.442300796508789\n",
      "Predicting:\n",
      "0.24682235717773438\n",
      "Test accuracy:  0.9862579281183932\n"
     ]
    }
   ],
   "source": [
    "for para in [200,2000,5000]:\n",
    "\n",
    "\n",
    "    tr_dx = np.array(trainingMat).astype(float)\n",
    "    tr_dy = np.array(hwLabels).astype(float)\n",
    "    ts_dx = np.array(testMat).astype(float)\n",
    "    ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "    svm_model = svm.SVC(\n",
    "                                        max_iter =  para,\n",
    "                           probability = True,\n",
    "                            kernel = 'linear',decision_function_shape='ovr'\n",
    "                           )\n",
    "\n",
    "\n",
    "    tm_st = time.time() \n",
    "    svm_model.fit(tr_dx,tr_dy)\n",
    "    tm_ed = time.time()\n",
    "    print(\"Training:\")\n",
    "    print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "    tm_st = time.time()        \n",
    "    test_preds = svm_model.predict_proba(ts_dx)\n",
    "    tm_ed = time.time()\n",
    "    print(\"Predicting:\")\n",
    "    print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "    preds_1 = test_preds.argmax(axis=1)\n",
    "    ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "    print(\"Test accuracy: \" ,ts_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stupid-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "1.4982478618621826\n",
      "Predicting:\n",
      "0.2429964542388916\n",
      "Test accuracy:  0.985200845665962\n",
      "Training:\n",
      "1.4414925575256348\n",
      "Predicting:\n",
      "0.24317312240600586\n",
      "Test accuracy:  0.985200845665962\n",
      "Training:\n",
      "1.4936692714691162\n",
      "Predicting:\n",
      "0.24358201026916504\n",
      "Test accuracy:  0.9873150105708245\n"
     ]
    }
   ],
   "source": [
    "for para in [1,25,50]:\n",
    "\n",
    "\n",
    "    tr_dx = np.array(trainingMat).astype(float)\n",
    "    tr_dy = np.array(hwLabels).astype(float)\n",
    "    ts_dx = np.array(testMat).astype(float)\n",
    "    ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "    svm_model = svm.SVC(\n",
    "                                        C =  para,\n",
    "                           probability = True,\n",
    "                            kernel = 'linear',decision_function_shape='ovr'\n",
    "                           )\n",
    "\n",
    "\n",
    "    tm_st = time.time() \n",
    "    svm_model.fit(tr_dx,tr_dy)\n",
    "    tm_ed = time.time()\n",
    "    print(\"Training:\")\n",
    "    print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "    tm_st = time.time()        \n",
    "    test_preds = svm_model.predict_proba(ts_dx)\n",
    "    tm_ed = time.time()\n",
    "    print(\"Predicting:\")\n",
    "    print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "    preds_1 = test_preds.argmax(axis=1)\n",
    "    ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "    print(\"Test accuracy: \" ,ts_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-classic",
   "metadata": {},
   "source": [
    "### the Bayes optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "quantitative-huntington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: 0 SVM\n",
      "|   iter    |  target   |     C     | max_iter  |    tol    |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9752   \u001b[0m | \u001b[0m21.43    \u001b[0m | \u001b[0m3.602e+03\u001b[0m | \u001b[0m0.0002144\u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9747   \u001b[0m | \u001b[0m15.81    \u001b[0m | \u001b[0m734.6    \u001b[0m | \u001b[0m0.09243  \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.9752   \u001b[0m | \u001b[0m10.13    \u001b[0m | \u001b[0m1.728e+03\u001b[0m | \u001b[0m0.3968   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.9741   \u001b[0m | \u001b[0m27.4     \u001b[0m | \u001b[0m2.097e+03\u001b[0m | \u001b[0m0.6853   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9752   \u001b[0m | \u001b[0m11.02    \u001b[0m | \u001b[0m4.391e+03\u001b[0m | \u001b[0m0.02748  \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9731   \u001b[0m | \u001b[0m12.4     \u001b[0m | \u001b[0m4.391e+03\u001b[0m | \u001b[0m0.8158   \u001b[0m |\n",
      "| \u001b[95m7        \u001b[0m | \u001b[95m0.9762   \u001b[0m | \u001b[95m27.08    \u001b[0m | \u001b[95m3.937e+03\u001b[0m | \u001b[95m0.175    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.9721   \u001b[0m | \u001b[0m30.2     \u001b[0m | \u001b[0m1.306e+03\u001b[0m | \u001b[0m0.7468   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9726   \u001b[0m | \u001b[0m12.15    \u001b[0m | \u001b[0m778.8    \u001b[0m | \u001b[0m0.9473   \u001b[0m |\n",
      "| \u001b[95m10       \u001b[0m | \u001b[95m0.9767   \u001b[0m | \u001b[95m36.59    \u001b[0m | \u001b[95m3.643e+03\u001b[0m | \u001b[95m0.1948   \u001b[0m |\n",
      "=============================================================\n",
      "{'target': 0.9767227644562263, 'params': {'C': 36.58654654217979, 'max_iter': 3643.3314572396093, 'tol': 0.19476856277911697}}\n",
      "Tuning:\n",
      "11.301583528518677\n",
      "Training:\n",
      "1.2195179462432861\n",
      "Predicting:\n",
      "0.22110891342163086\n",
      "Test accuracy:  0.985200845665962\n",
      "Test recall:  0.985200845665962\n",
      "Test precision:  0.9854245234168553\n",
      "Test f1_s:  0.9852001145923238\n",
      "5-fold Test accuracy:  0.9767227644562263\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "\n",
    "        'max_iter': (1, 5000),\n",
    "        'tol': (0.0001,1),\n",
    "        'C': (1, 50)\n",
    "                }\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'SVM', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "svm_model = svm.SVC(\n",
    "            max_iter= int (params['params']['max_iter']),\n",
    "                                    tol =  params['params']['tol'],\n",
    "                                C= params['params']['C'],\n",
    "                       probability = True,\n",
    "                        kernel = 'linear',decision_function_shape='ovr'\n",
    "                       )\n",
    "\n",
    "        \n",
    "tm_st = time.time() \n",
    "svm_model.fit(tr_dx,tr_dy)\n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "tm_st = time.time()        \n",
    "test_preds = svm_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "\n",
    "\n",
    "val = cross_val_score(svm_model,tr_dx,tr_dy,scoring = 'accuracy',cv = 5,n_jobs = 10).mean()        \n",
    "print(\"5-fold Test accuracy: \" ,val)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-register",
   "metadata": {},
   "source": [
    "## Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cleared-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model(C,max_iter,tol):\n",
    "    \n",
    "    \n",
    "    \n",
    "    svm_model = svm.SVC(\n",
    "        max_iter= int (max_iter),\n",
    "                                    tol =  tol,\n",
    "                                C= C,\n",
    "                       probability = True,\n",
    "                        kernel = 'sigmoid'\n",
    "                       )\n",
    "    \n",
    "    val = cross_val_score(svm_model,tr_dx,tr_dy,scoring = 'accuracy',cv = 5,n_jobs = 10).mean()\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "def tune( tasks, nb, nit, model_name, param_tune):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        #res_output = f\"{task}year_{model_name}.txt\"\n",
    "        #model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        BO = BayesianOptimization( f = SVM_model,pbounds = param_tune,verbose = 2,random_state = 1 )\n",
    "        \n",
    "        BO.maximize(n_iter=5)\n",
    "        print(BO.max)\n",
    "        return BO.max\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "medieval-grammar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: 0 SVM\n",
      "|   iter    |  target   |     C     | max_iter  |    tol    |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9017   \u001b[0m | \u001b[0m21.43    \u001b[0m | \u001b[0m3.602e+03\u001b[0m | \u001b[0m0.0002144\u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.9059   \u001b[0m | \u001b[95m15.81    \u001b[0m | \u001b[95m734.6    \u001b[0m | \u001b[95m0.09243  \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.9142   \u001b[0m | \u001b[95m10.13    \u001b[0m | \u001b[95m1.728e+03\u001b[0m | \u001b[95m0.3968   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.8971   \u001b[0m | \u001b[0m27.4     \u001b[0m | \u001b[0m2.097e+03\u001b[0m | \u001b[0m0.6853   \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m0.9193   \u001b[0m | \u001b[95m11.02    \u001b[0m | \u001b[95m4.391e+03\u001b[0m | \u001b[95m0.02748  \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9131   \u001b[0m | \u001b[0m12.4     \u001b[0m | \u001b[0m4.391e+03\u001b[0m | \u001b[0m0.8158   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9152   \u001b[0m | \u001b[0m11.27    \u001b[0m | \u001b[0m4.388e+03\u001b[0m | \u001b[0m0.7478   \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m0.9214   \u001b[0m | \u001b[95m7.438    \u001b[0m | \u001b[95m4.389e+03\u001b[0m | \u001b[95m0.6423   \u001b[0m |\n",
      "| \u001b[95m9        \u001b[0m | \u001b[95m0.9255   \u001b[0m | \u001b[95m6.228    \u001b[0m | \u001b[95m4.391e+03\u001b[0m | \u001b[95m0.2384   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.925    \u001b[0m | \u001b[0m6.481    \u001b[0m | \u001b[0m4.397e+03\u001b[0m | \u001b[0m0.621    \u001b[0m |\n",
      "=============================================================\n",
      "{'target': 0.9255372133188737, 'params': {'C': 6.227538554955462, 'max_iter': 4391.3007169872735, 'tol': 0.23837596522068014}}\n",
      "Tuning:\n",
      "10.853391647338867\n",
      "Training:\n",
      "1.249006986618042\n",
      "Predicting:\n",
      "0.22066950798034668\n",
      "Test accuracy:  0.9397463002114165\n",
      "Test recall:  0.9397463002114165\n",
      "Test precision:  0.9418452389196608\n",
      "Test f1_s:  0.9400083312524807\n",
      "5-fold Test accuracy:  0.9255372133188737\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "\n",
    "        'max_iter': (1, 5000),\n",
    "        'tol': (0.0001,1),\n",
    "        'C': (1, 50)\n",
    "                }\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'SVM', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "svm_model = svm.SVC(\n",
    "            max_iter= int (params['params']['max_iter']),\n",
    "                                    tol =  params['params']['tol'],\n",
    "                                C= params['params']['C'],\n",
    "                       probability = True,\n",
    "                        kernel = 'sigmoid',decision_function_shape='ovr'\n",
    "                       )\n",
    "\n",
    "        \n",
    "tm_st = time.time() \n",
    "svm_model.fit(tr_dx,tr_dy)\n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "tm_st = time.time()        \n",
    "test_preds = svm_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "val = cross_val_score(svm_model,tr_dx,tr_dy,scoring = 'accuracy',cv = 5,n_jobs = 10).mean()        \n",
    "print(\"5-fold Test accuracy: \" ,val)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-wiring",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "judicial-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(n_estimators,gamma, max_depth,min_child_weight):\n",
    "    \n",
    "    \n",
    "    \n",
    "    xgb_model = XGBClassifier(max_depth = int(max_depth), \n",
    "                              n_estimators = int(n_estimators) ,\n",
    "                              objective = 'binary:logistic',\n",
    "                                booster = 'gbtree', \n",
    "                              gamma = min(gamma,1),\n",
    "                              min_child_weight = min(min_child_weight,1),\n",
    "                              random_state = 77)\n",
    "                              #scale_pos_weight = min(scale_pos_weight,1),random_state = 77,decision_function_shape='ovr' )\n",
    "    \n",
    "    val = cross_val_score(xgb_model,tr_dx,tr_dy,scoring = 'accuracy',cv = 5,n_jobs = 10).mean()\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "def tune( tasks, nb, nit, model_name, param_tune):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        #res_output = f\"{task}year_{model_name}.txt\"\n",
    "        #model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        BO = BayesianOptimization( f = xgb_cv,pbounds = param_tune,verbose = 2,random_state = 777 )\n",
    "        \n",
    "        BO.maximize(n_iter=5)\n",
    "        print(BO.max)\n",
    "        return BO.max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-monitor",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "substantial-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: 0 XG\n",
      "|   iter    |  target   |   gamma   | max_depth | min_ch... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8965   \u001b[0m | \u001b[0m0.1527   \u001b[0m | \u001b[0m3.721    \u001b[0m | \u001b[0m0.06204  \u001b[0m | \u001b[0m23.53    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.882    \u001b[0m | \u001b[0m0.8353   \u001b[0m | \u001b[0m9.343    \u001b[0m | \u001b[0m0.727    \u001b[0m | \u001b[0m38.66    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.8426   \u001b[0m | \u001b[0m0.2692   \u001b[0m | \u001b[0m6.796    \u001b[0m | \u001b[0m0.09337  \u001b[0m | \u001b[0m4.905    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.8902   \u001b[0m | \u001b[0m0.5896   \u001b[0m | \u001b[0m4.09     \u001b[0m | \u001b[0m0.9889   \u001b[0m | \u001b[0m31.7     \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.88     \u001b[0m | \u001b[0m0.6818   \u001b[0m | \u001b[0m5.97     \u001b[0m | \u001b[0m0.2689   \u001b[0m | \u001b[0m19.29    \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.8986   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m50.0     \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.8923   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8902   \u001b[0m | \u001b[0m0.4111   \u001b[0m | \u001b[0m4.263    \u001b[0m | \u001b[0m0.7557   \u001b[0m | \u001b[0m31.6     \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.8903   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m42.42    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.8841   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m26.4     \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 0.8985609965635739, 'params': {'gamma': 0.0, 'max_depth': 1.0, 'min_child_weight': 0.0, 'n_estimators': 50.0}}\n",
      "Tuning:\n",
      "7.30967116355896\n",
      "Training:\n",
      "28.250094890594482\n",
      "Predicting:\n",
      "0.0239105224609375\n",
      "Test accuracy:  0.9217758985200846\n",
      "Test recall:  0.9217758985200846\n",
      "Test precision:  0.9232502171114332\n",
      "Test f1_s:  0.921936179675522\n"
     ]
    }
   ],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.75, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "\n",
    "\n",
    "            'max_depth' :(1,10),\n",
    "            'n_estimators' :(1,50),\n",
    "\n",
    "            'gamma': (0,1), \n",
    "            'min_child_weight' : (0,1)\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "xgb_model = XGBClassifier(max_depth = int(params['params']['max_depth']),\n",
    "                                  \n",
    "                                  n_estimators = int(params['params']['n_estimators']), \n",
    "                                  objective = 'binary:logistic',\n",
    "                                 booster = 'gbtree', \n",
    "                                  gamma = params['params']['gamma'], \n",
    "                                  min_child_weight = params['params']['min_child_weight'],\n",
    "                                  #scale_pos_weight= params['params']['scale_pos_weight'],\n",
    "                                 random_state = 77)\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "xgb_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = xgb_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-ownership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dynamic-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: 0 XG\n",
      "|   iter    |  target   |   gamma   | max_depth | min_ch... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9369   \u001b[0m | \u001b[0m0.1527   \u001b[0m | \u001b[0m3.721    \u001b[0m | \u001b[0m0.06204  \u001b[0m | \u001b[0m23.53    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9255   \u001b[0m | \u001b[0m0.8353   \u001b[0m | \u001b[0m9.343    \u001b[0m | \u001b[0m0.727    \u001b[0m | \u001b[0m38.66    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.9027   \u001b[0m | \u001b[0m0.2692   \u001b[0m | \u001b[0m6.796    \u001b[0m | \u001b[0m0.09337  \u001b[0m | \u001b[0m4.905    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.9317   \u001b[0m | \u001b[0m0.5896   \u001b[0m | \u001b[0m4.09     \u001b[0m | \u001b[0m0.9889   \u001b[0m | \u001b[0m31.7     \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m0.9379   \u001b[0m | \u001b[95m0.6818   \u001b[0m | \u001b[95m5.97     \u001b[0m | \u001b[95m0.2689   \u001b[0m | \u001b[95m19.29    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9296   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9234   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m24.58    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8924   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m18.3     \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9338   \u001b[0m | \u001b[0m0.6832   \u001b[0m | \u001b[0m6.83     \u001b[0m | \u001b[0m0.4113   \u001b[0m | \u001b[0m19.52    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9338   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m5.453    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m21.67    \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 0.937898616526895, 'params': {'gamma': 0.6817792797809532, 'max_depth': 5.970311323634439, 'min_child_weight': 0.2688600578882592, 'n_estimators': 19.289709935405487}}\n",
      "Tuning:\n",
      "7.958837509155273\n",
      "Training:\n",
      "48.741735219955444\n",
      "Predicting:\n",
      "0.016968727111816406\n",
      "Test accuracy:  0.9492600422832981\n",
      "Test recall:  0.9492600422832981\n",
      "Test precision:  0.9507346334102877\n",
      "Test f1_s:  0.9494933738896708\n"
     ]
    }
   ],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.5, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "\n",
    "\n",
    "            'max_depth' :(1,10),\n",
    "            'n_estimators' :(1,50),\n",
    "\n",
    "            'gamma': (0,1), \n",
    "            'min_child_weight' : (0,1)\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "xgb_model = XGBClassifier(max_depth = int(params['params']['max_depth']),\n",
    "                                  \n",
    "                                  n_estimators = int(params['params']['n_estimators']), \n",
    "                                  objective = 'binary:logistic',\n",
    "                                 booster = 'gbtree', \n",
    "                                  gamma = params['params']['gamma'], \n",
    "                                  min_child_weight = params['params']['min_child_weight'],\n",
    "                                  #scale_pos_weight= params['params']['scale_pos_weight'],\n",
    "                                 random_state = 77)\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "xgb_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = xgb_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "protected-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: 0 XG\n",
      "|   iter    |  target   |   gamma   | max_depth | min_ch... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9469   \u001b[0m | \u001b[0m0.1527   \u001b[0m | \u001b[0m3.721    \u001b[0m | \u001b[0m0.06204  \u001b[0m | \u001b[0m23.53    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9366   \u001b[0m | \u001b[0m0.8353   \u001b[0m | \u001b[0m9.343    \u001b[0m | \u001b[0m0.727    \u001b[0m | \u001b[0m38.66    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.9041   \u001b[0m | \u001b[0m0.2692   \u001b[0m | \u001b[0m6.796    \u001b[0m | \u001b[0m0.09337  \u001b[0m | \u001b[0m4.905    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.9421   \u001b[0m | \u001b[0m0.5896   \u001b[0m | \u001b[0m4.09     \u001b[0m | \u001b[0m0.9889   \u001b[0m | \u001b[0m31.7     \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9338   \u001b[0m | \u001b[0m0.6818   \u001b[0m | \u001b[0m5.97     \u001b[0m | \u001b[0m0.2689   \u001b[0m | \u001b[0m19.29    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9241   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9366   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m27.46    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.9028   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m26.29    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9317   \u001b[0m | \u001b[0m0.6863   \u001b[0m | \u001b[0m8.563    \u001b[0m | \u001b[0m0.6988   \u001b[0m | \u001b[0m19.99    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9338   \u001b[0m | \u001b[0m0.2114   \u001b[0m | \u001b[0m2.93     \u001b[0m | \u001b[0m0.00309  \u001b[0m | \u001b[0m23.55    \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 0.9468965517241379, 'params': {'gamma': 0.152663734901322, 'max_depth': 3.721209487367691, 'min_child_weight': 0.062036414714562005, 'n_estimators': 23.533156738839473}}\n",
      "Tuning:\n",
      "11.371503591537476\n",
      "Training:\n",
      "35.89273428916931\n",
      "Predicting:\n",
      "0.01790761947631836\n",
      "Test accuracy:  0.9577167019027484\n",
      "Test recall:  0.9577167019027484\n",
      "Test precision:  0.959349363374193\n",
      "Test f1_s:  0.9579237840194995\n"
     ]
    }
   ],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.25, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "\n",
    "\n",
    "            'max_depth' :(1,10),\n",
    "            'n_estimators' :(1,50),\n",
    "\n",
    "            'gamma': (0,1), \n",
    "            'min_child_weight' : (0,1)\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "xgb_model = XGBClassifier(max_depth = int(params['params']['max_depth']),\n",
    "                                  \n",
    "                                  n_estimators = int(params['params']['n_estimators']), \n",
    "                                  objective = 'binary:logistic',\n",
    "                                 booster = 'gbtree', \n",
    "                                  gamma = params['params']['gamma'], \n",
    "                                  min_child_weight = params['params']['min_child_weight'],\n",
    "                                  #scale_pos_weight= params['params']['scale_pos_weight'],\n",
    "                                 random_state = 77)\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "xgb_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = xgb_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-player",
   "metadata": {},
   "source": [
    "### the Bayes optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "breeding-entertainment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: 0 XG\n",
      "|   iter    |  target   |   gamma   | max_depth | min_ch... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9566   \u001b[0m | \u001b[0m0.1527   \u001b[0m | \u001b[0m3.721    \u001b[0m | \u001b[0m0.06204  \u001b[0m | \u001b[0m23.53    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9478   \u001b[0m | \u001b[0m0.8353   \u001b[0m | \u001b[0m9.343    \u001b[0m | \u001b[0m0.727    \u001b[0m | \u001b[0m38.66    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.9266   \u001b[0m | \u001b[0m0.2692   \u001b[0m | \u001b[0m6.796    \u001b[0m | \u001b[0m0.09337  \u001b[0m | \u001b[0m4.905    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.9509   \u001b[0m | \u001b[0m0.5896   \u001b[0m | \u001b[0m4.09     \u001b[0m | \u001b[0m0.9889   \u001b[0m | \u001b[0m31.7     \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9447   \u001b[0m | \u001b[0m0.6818   \u001b[0m | \u001b[0m5.97     \u001b[0m | \u001b[0m0.2689   \u001b[0m | \u001b[0m19.29    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9266   \u001b[0m | \u001b[0m0.08175  \u001b[0m | \u001b[0m6.45     \u001b[0m | \u001b[0m0.252    \u001b[0m | \u001b[0m4.587    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9369   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.9524   \u001b[0m | \u001b[0m0.5531   \u001b[0m | \u001b[0m9.999    \u001b[0m | \u001b[0m0.01329  \u001b[0m | \u001b[0m27.86    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9074   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m26.15    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9524   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m5.446    \u001b[0m | \u001b[0m0.1005   \u001b[0m | \u001b[0m22.6     \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 0.9565637091483579, 'params': {'gamma': 0.152663734901322, 'max_depth': 3.721209487367691, 'min_child_weight': 0.062036414714562005, 'n_estimators': 23.533156738839473}}\n",
      "Tuning:\n",
      "15.059848308563232\n",
      "Training:\n",
      "38.41300439834595\n",
      "Predicting:\n",
      "0.017200231552124023\n",
      "Test accuracy:  0.9651162790697675\n",
      "Test recall:  0.9651162790697675\n",
      "Test precision:  0.9656699420751614\n",
      "Test f1_s:  0.9652132903150598\n",
      "5-fold Test accuracy:  0.9565637091483579\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "\n",
    "\n",
    "            'max_depth' :(1,10),\n",
    "            'n_estimators' :(1,50),\n",
    "\n",
    "            'gamma': (0,1), \n",
    "            'min_child_weight' : (0,1)\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "xgb_model = XGBClassifier(max_depth = int(params['params']['max_depth']),\n",
    "                                  \n",
    "                                  n_estimators = int(params['params']['n_estimators']), \n",
    "                                  objective = 'binary:logistic',\n",
    "                                 booster = 'gbtree', \n",
    "                                  gamma = params['params']['gamma'], \n",
    "                                  min_child_weight = params['params']['min_child_weight'],\n",
    "                                  #scale_pos_weight= params['params']['scale_pos_weight'],\n",
    "                                 random_state = 77)\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "xgb_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = xgb_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "val = cross_val_score(xgb_model,tr_dx,tr_dy,scoring = 'accuracy',cv = 5,n_jobs = 10).mean()        \n",
    "print(\"5-fold Test accuracy: \" ,val)          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-numbers",
   "metadata": {},
   "source": [
    "### Train on the whole dataset and tune the parameter individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "opponent-ancient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "33.21349549293518\n",
      "Predicting:\n",
      "0.016661405563354492\n",
      "Test accuracy:  0.9651162790697675\n",
      "Training:\n",
      "105.60733532905579\n",
      "Predicting:\n",
      "0.020355939865112305\n",
      "Test accuracy:  0.9704016913319239\n",
      "Training:\n",
      "181.02379179000854\n",
      "Predicting:\n",
      "0.019367694854736328\n",
      "Test accuracy:  0.9704016913319239\n"
     ]
    }
   ],
   "source": [
    "for para in [10,50,100]:\n",
    "    \n",
    "    import sys\n",
    "\n",
    "    tr_dx = np.array(trainingMat).astype(float)\n",
    "    tr_dy = np.array(hwLabels).astype(float)\n",
    "    ts_dx = np.array(testMat).astype(float)\n",
    "    ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "\n",
    "                                      n_estimators = para, \n",
    "                                      objective = 'binary:logistic',\n",
    "                                     booster = 'gbtree', \n",
    "\n",
    "\n",
    "                                     random_state = 77)\n",
    "\n",
    "\n",
    "    tm_st = time.time()\n",
    "    xgb_model.fit(tr_dx,tr_dy)     \n",
    "    tm_ed = time.time()\n",
    "    print(\"Training:\")\n",
    "    print(tm_ed-tm_st)\n",
    "\n",
    "    tm_st = time.time()\n",
    "    test_preds = xgb_model.predict_proba(ts_dx)\n",
    "    tm_ed = time.time()\n",
    "    print(\"Predicting:\")\n",
    "    print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "    preds_1 = test_preds.argmax(axis=1)\n",
    "    ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "    print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-champagne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "144.89028120040894\n",
      "Predicting:\n",
      "0.018473148345947266\n",
      "Test accuracy:  0.9714587737843552\n"
     ]
    }
   ],
   "source": [
    "for para in [5,10,20]:\n",
    "    \n",
    "    import sys\n",
    "\n",
    "    tr_dx = np.array(trainingMat).astype(float)\n",
    "    tr_dy = np.array(hwLabels).astype(float)\n",
    "    ts_dx = np.array(testMat).astype(float)\n",
    "    ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "\n",
    "                                      max_depth = para, \n",
    "                                      objective = 'binary:logistic',\n",
    "                                     booster = 'gbtree', \n",
    "\n",
    "\n",
    "                                     random_state = 77)\n",
    "\n",
    "\n",
    "    tm_st = time.time()\n",
    "    xgb_model.fit(tr_dx,tr_dy)     \n",
    "    tm_ed = time.time()\n",
    "    print(\"Training:\")\n",
    "    print(tm_ed-tm_st)\n",
    "\n",
    "    tm_st = time.time()\n",
    "    test_preds = xgb_model.predict_proba(ts_dx)\n",
    "    tm_ed = time.time()\n",
    "    print(\"Predicting:\")\n",
    "    print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "    preds_1 = test_preds.argmax(axis=1)\n",
    "    ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "    print(\"Test accuracy: \" ,ts_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-panic",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(max_depth):\n",
    "    \n",
    "    \n",
    "    \n",
    "    xgb_model = DecisionTreeClassifier(max_depth = int(max_depth), \n",
    "                              #max_leaf_nodes = int(max_leaf_nodes),\n",
    "                              \n",
    "                             )\n",
    "    \n",
    "    val = cross_val_score(xgb_model,tr_dx,tr_dy,scoring = 'accuracy',cv = 5,n_jobs = 30).mean()\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "def tune( tasks, nb, nit, model_name, param_tune):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        #res_output = f\"{task}year_{model_name}.txt\"\n",
    "        #model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        BO = BayesianOptimization( f = xgb_cv,pbounds = param_tune,verbose = 2,random_state = 777 )\n",
    "        \n",
    "        BO.maximize(n_iter=5)\n",
    "        print(BO.max)\n",
    "        return BO.max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.75, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "            'max_depth' :(1,20),\n",
    "            #'min_samples_split' : (2,10),\n",
    "            #'min_samples_leaf' : (1,100), \n",
    "            #'max_leaf_nodes' :(2,100),\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth = int(params['params']['max_depth']),\n",
    "                                  #min_samples_split = int(params['params']['min_samples_split']), \n",
    "                                  #min_samples_leaf = params['params']['min_samples_leaf'], \n",
    "                                  #max_leaf_nodes = int(params['params']['max_leaf_nodes']),\n",
    "                                 random_state = 77)\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "dt_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = dt_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.5, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "            'max_depth' :(1,20),\n",
    "            #'min_samples_split' : (2,10),\n",
    "            #'min_samples_leaf' : (1,100), \n",
    "            #'max_leaf_nodes' :(2,100),\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth = int(params['params']['max_depth']),\n",
    "                                  #min_samples_split = int(params['params']['min_samples_split']), \n",
    "                                  #min_samples_leaf = params['params']['min_samples_leaf'], \n",
    "                                  #max_leaf_nodes = int(params['params']['max_leaf_nodes']),\n",
    "                                 random_state = 77)\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "dt_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = dt_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.25, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "            'max_depth' :(1,20),\n",
    "            #'min_samples_split' : (2,10),\n",
    "            #'min_samples_leaf' : (1,100), \n",
    "            #'max_leaf_nodes' :(2,100),\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth = int(params['params']['max_depth']),\n",
    "                                  #min_samples_split = int(params['params']['min_samples_split']), \n",
    "                                  #min_samples_leaf = params['params']['min_samples_leaf'], \n",
    "                                  #max_leaf_nodes = int(params['params']['max_leaf_nodes']),\n",
    "                                 random_state = 77)\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "dt_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = dt_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "            'max_depth' :(1,20),\n",
    "            #'min_samples_split' : (2,10),\n",
    "            #'min_samples_leaf' : (1,100), \n",
    "            #'max_leaf_nodes' :(2,100),\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth = int(params['params']['max_depth']),\n",
    "                                  #min_samples_split = int(params['params']['min_samples_split']), \n",
    "                                  #min_samples_leaf = params['params']['min_samples_leaf'], \n",
    "                                  #max_leaf_nodes = int(params['params']['max_leaf_nodes']),\n",
    "                                 random_state = 77)\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "dt_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = dt_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "val = cross_val_score(dt_model,tr_dx,tr_dy,scoring = 'accuracy',cv = 5,n_jobs = 10).mean()        \n",
    "print(\"5-fold Test accuracy: \" ,val)          \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-buddy",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(n_neighbors):\n",
    "    \n",
    "    \n",
    "    \n",
    "    xgb_model = KNeighborsClassifier(n_neighbors = int(n_neighbors),\n",
    "                              \n",
    "                             )\n",
    "    \n",
    "    val = cross_val_score(xgb_model,tr_dx,tr_dy,scoring = 'accuracy',cv = 5,n_jobs = 30).mean()\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "def tune( tasks, nb, nit, model_name, param_tune):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        #res_output = f\"{task}year_{model_name}.txt\"\n",
    "        #model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        BO = BayesianOptimization( f = xgb_cv,pbounds = param_tune,verbose = 2,random_state = 777 )\n",
    "        \n",
    "        BO.maximize(n_iter=5)\n",
    "        print(BO.max)\n",
    "        return BO.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.75, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "            'n_neighbors' :(1,10)\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "kn_model = KNeighborsClassifier(n_neighbors = int(params['params']['n_neighbors']))\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "kn_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = kn_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.5, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "            'n_neighbors' :(1,10)\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "kn_model = KNeighborsClassifier(n_neighbors = int(params['params']['n_neighbors']))\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "kn_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = kn_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.25, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "            'n_neighbors' :(1,10)\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "kn_model = KNeighborsClassifier(n_neighbors = int(params['params']['n_neighbors']))\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "kn_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = kn_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_tune = {\n",
    "            'n_neighbors' :(1,10)\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "params = tune(tasks = [i], nb = 10, nit = 20, model_name = 'XG', param_tune = param_tune)\n",
    "tm_ed = time.time()\n",
    "print(\"Tuning:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "kn_model = KNeighborsClassifier(n_neighbors = int(params['params']['n_neighbors']))\n",
    "\n",
    "        \n",
    "tm_st = time.time()\n",
    "kn_model.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = kn_model.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n",
    "\n",
    "        \n",
    "val = cross_val_score(kn_model,tr_dx,tr_dy,scoring = 'accuracy',cv = 5,n_jobs = 10).mean()        \n",
    "print(\"5-fold Test accuracy: \" ,val)          \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-active",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.75, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation = \"relu\",solver = \"adam\", batch_size = 2, learning_rate_init = 0.001, hidden_layer_sizes=(20, 10), max_iter=200, random_state=42)\n",
    "\n",
    "\n",
    "mlp.fit(tr_dx, tr_dy)\n",
    "\n",
    "\n",
    "iterations = range(1, len(mlp.loss_curve_) + 1)\n",
    "loss_values = mlp.loss_curve_\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Curve, lr = 0.01, batch_size = 2\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iterations, loss_values, label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "mlp.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = mlp.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tr_preds = mlp.predict_proba(tr_dx)\n",
    "preds_tr = tr_preds.argmax(axis=1)\n",
    "tr_accuracy_score = accuracy_score(tr_dy, preds_tr)\n",
    "print(\"Training accuracy: \" ,tr_accuracy_score)\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.5, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation = \"relu\",solver = \"adam\", batch_size = 2, learning_rate_init = 0.001, hidden_layer_sizes=(20, 10), max_iter=200, random_state=42)\n",
    "\n",
    "\n",
    "mlp.fit(tr_dx, tr_dy)\n",
    "\n",
    "\n",
    "iterations = range(1, len(mlp.loss_curve_) + 1)\n",
    "loss_values = mlp.loss_curve_\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Curve, lr = 0.01, batch_size = 2\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iterations, loss_values, label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "mlp.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = mlp.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tr_preds = mlp.predict_proba(tr_dx)\n",
    "preds_tr = tr_preds.argmax(axis=1)\n",
    "tr_accuracy_score = accuracy_score(tr_dy, preds_tr)\n",
    "print(\"Training accuracy: \" ,tr_accuracy_score)\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr,_1, ltr,_2 = train_test_split(trainingMat,hwLabels, test_size=0.25, random_state=42)\n",
    "\n",
    "import sys\n",
    "\n",
    "tr_dx = np.array(dtr).astype(float)\n",
    "tr_dy = np.array(ltr).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation = \"relu\",solver = \"adam\", batch_size = 2, learning_rate_init = 0.001, hidden_layer_sizes=(20, 10), max_iter=200, random_state=42)\n",
    "\n",
    "\n",
    "mlp.fit(tr_dx, tr_dy)\n",
    "\n",
    "\n",
    "iterations = range(1, len(mlp.loss_curve_) + 1)\n",
    "loss_values = mlp.loss_curve_\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Curve, lr = 0.01, batch_size = 2\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iterations, loss_values, label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "mlp.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = mlp.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tr_preds = mlp.predict_proba(tr_dx)\n",
    "preds_tr = tr_preds.argmax(axis=1)\n",
    "tr_accuracy_score = accuracy_score(tr_dy, preds_tr)\n",
    "print(\"Training accuracy: \" ,tr_accuracy_score)\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation = \"relu\",solver = \"adam\", batch_size = 2, learning_rate_init = 0.01, hidden_layer_sizes=(20, 10), max_iter=200, random_state=42)\n",
    "\n",
    "\n",
    "mlp.fit(tr_dx, tr_dy)\n",
    "\n",
    "\n",
    "iterations = range(1, len(mlp.loss_curve_) + 1)\n",
    "loss_values = mlp.loss_curve_\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Curve, lr = 0.01, batch_size = 2\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iterations, loss_values, label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "mlp.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = mlp.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tr_preds = mlp.predict_proba(tr_dx)\n",
    "preds_tr = tr_preds.argmax(axis=1)\n",
    "tr_accuracy_score = accuracy_score(tr_dy, preds_tr)\n",
    "print(\"Training accuracy: \" ,tr_accuracy_score)\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation = \"relu\",solver = \"adam\", batch_size = 2, learning_rate_init = 0.001, hidden_layer_sizes=(20, 10), max_iter=200, random_state=42)\n",
    "\n",
    "\n",
    "mlp.fit(tr_dx, tr_dy)\n",
    "\n",
    "\n",
    "iterations = range(1, len(mlp.loss_curve_) + 1)\n",
    "loss_values = mlp.loss_curve_\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Curve, lr = 0.001, batch_size = 2\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iterations, loss_values, label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "mlp.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = mlp.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tr_preds = mlp.predict_proba(tr_dx)\n",
    "preds_tr = tr_preds.argmax(axis=1)\n",
    "tr_accuracy_score = accuracy_score(tr_dy, preds_tr)\n",
    "print(\"Training accuracy: \" ,tr_accuracy_score)\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation = \"relu\",solver = \"adam\", batch_size = 2, learning_rate_init = 0.0001, hidden_layer_sizes=(20, 10), max_iter=200, random_state=42)\n",
    "\n",
    "\n",
    "mlp.fit(tr_dx, tr_dy)\n",
    "\n",
    "\n",
    "iterations = range(1, len(mlp.loss_curve_) + 1)\n",
    "loss_values = mlp.loss_curve_\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Curve, lr = 0.0001, batch_size = 2\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iterations, loss_values, label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "mlp.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = mlp.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-bullet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation = \"relu\",solver = \"adam\", batch_size = 5, learning_rate_init = 0.001, hidden_layer_sizes=(20, 10), max_iter=200, random_state=42)\n",
    "\n",
    "\n",
    "mlp.fit(tr_dx, tr_dy)\n",
    "\n",
    "\n",
    "iterations = range(1, len(mlp.loss_curve_) + 1)\n",
    "loss_values = mlp.loss_curve_\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Curve, lr = 0.001, batch_size = 5\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iterations, loss_values, label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "mlp.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = mlp.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation = \"relu\",solver = \"adam\", batch_size = 10, learning_rate_init = 0.001, hidden_layer_sizes=(20, 10), max_iter=200, random_state=42)\n",
    "\n",
    "\n",
    "mlp.fit(tr_dx, tr_dy)\n",
    "\n",
    "\n",
    "iterations = range(1, len(mlp.loss_curve_) + 1)\n",
    "loss_values = mlp.loss_curve_\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Curve, lr = 0.001, batch_size = 10\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iterations, loss_values, label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "mlp.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = mlp.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "tr_dx = np.array(trainingMat).astype(float)\n",
    "tr_dy = np.array(hwLabels).astype(float)\n",
    "ts_dx = np.array(testMat).astype(float)\n",
    "ts_dy = np.array(tsLabels).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation = \"relu\",solver = \"adam\", batch_size = 20, learning_rate_init = 0.001, hidden_layer_sizes=(20, 10), max_iter=200, random_state=42)\n",
    "\n",
    "\n",
    "mlp.fit(tr_dx, tr_dy)\n",
    "\n",
    "\n",
    "iterations = range(1, len(mlp.loss_curve_) + 1)\n",
    "loss_values = mlp.loss_curve_\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"MLP Training Curve, lr = 0.001, batch_size = 20\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iterations, loss_values, label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tm_st = time.time()\n",
    "mlp.fit(tr_dx,tr_dy)     \n",
    "tm_ed = time.time()\n",
    "print(\"Training:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "tm_st = time.time()\n",
    "test_preds = mlp.predict_proba(ts_dx)\n",
    "tm_ed = time.time()\n",
    "print(\"Predicting:\")\n",
    "print(tm_ed-tm_st)\n",
    "\n",
    "\n",
    "\n",
    "preds_1 = test_preds.argmax(axis=1)\n",
    "ts_accuracy_score = accuracy_score(ts_dy, preds_1)\n",
    "print(\"Test accuracy: \" ,ts_accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "        \n",
    "f1_s = f1_score(ts_dy, preds_1, average='weighted')\n",
    "\n",
    "print(\"Test recall: \",recall)\n",
    "print(\"Test precision: \",precision)        \n",
    "print(\"Test f1_s: \",f1_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-register",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-assembly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-sun.chengkun",
   "language": "python",
   "name": "sun.chengkun-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
